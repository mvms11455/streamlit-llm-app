from dotenv import load_dotenv
load_dotenv()


import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# --- LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ ---
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# --- å°‚é–€å®¶é¸æŠã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ ---
def get_system_prompt(expert_type):
    if expert_type == "A":
        return "ã‚ãªãŸã¯ç¡çœ ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ç¡çœ ã«æ‚©ã¿ã‚’æŠ±ãˆã¦ã„ã‚‹äººã«å¯¾ã—ã¦é©åˆ‡ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ã‚ã’ã¦ãã ã•ã„"
    elif expert_type == "B":
        return "ã‚ãªãŸã¯ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚è€åŒ–ã‚’é˜²æ­¢ã™ã‚‹ãŸã‚ã«ã„ã„é£Ÿã¹ç‰©ã€æ‚ªã„é£Ÿã¹ç‰©ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„"
    else:
        return "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"

# --- å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨é¸æŠå€¤ã‚’å—ã‘ã¦LLMã®å¿œç­”ã‚’å–å¾— ---
def get_llm_response(user_input, expert_type):
    messages = [
        SystemMessage(content=get_system_prompt(expert_type)),
        HumanMessage(content=user_input)
    ]
    result = llm(messages)
    return result.content

# --- Streamlit ã‚¢ãƒ—ãƒªæ§‹æˆ ---
st.set_page_config(page_title="å°‚é–€å®¶AIã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼", layout="centered")
st.title("ğŸ§  å°‚é–€å®¶AIã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼")

st.markdown("""
ã“ã®Webã‚¢ãƒ—ãƒªã§ã¯ã€æ¬¡ã®2ç¨®é¡ã®å°‚é–€å®¶AIã«ç›¸è«‡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š

- **Aï¼šç¡çœ ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼** â€” ç¡çœ ã«é–¢ã™ã‚‹æ‚©ã¿ã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚
- **Bï¼šãƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼** â€” è€åŒ–é˜²æ­¢ã‚’ç›®çš„ã¨ã—ãŸé£Ÿç”Ÿæ´»ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã„ã¾ã™ã€‚

ä¸‹è¨˜ã®ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰è³ªå•ã‚’å…¥åŠ›ã—ã€ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
""")

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
st.markdown("### ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ")
if "responses" not in st.session_state:
    st.session_state.responses = []  # éå»ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ä¿å­˜

with st.form(key="consult_form"):
    user_input = st.text_area("ã‚ãªãŸã®ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=150)
    expert_choice = st.radio("ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["Aï¼ˆç¡çœ ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ï¼‰", "Bï¼ˆãƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ï¼‰"])
    submit = st.form_submit_button("ç›¸è«‡ã™ã‚‹")

# å…¥åŠ›ãŒé€ä¿¡ã•ã‚ŒãŸã‚‰å‡¦ç†
if submit:
    if not user_input.strip():
        st.warning("ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        expert_type = "A" if expert_choice.startswith("A") else "B"
        with st.spinner("AIãŒå›ç­”ã‚’ä½œæˆä¸­ã§ã™..."):
            response = get_llm_response(user_input, expert_type)
        st.session_state.responses.append({"input": user_input, "response": response})
        st.success("AIã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸï¼")

# éå»ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
if st.session_state.responses:
    st.markdown("### éå»ã®ç›¸è«‡ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
    for i, entry in enumerate(st.session_state.responses, 1):
        st.markdown(f"**ç›¸è«‡ {i}:** {entry['input']}")
        st.markdown(f"**ã‚¢ãƒ‰ãƒã‚¤ã‚¹ {i}:** {entry['response']}")
        st.markdown("---")
